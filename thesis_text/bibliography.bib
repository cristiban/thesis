@article{abbottSynapticDepressionCortical1997,
  title = {Synaptic {{Depression}} and {{Cortical Gain Control}}},
  author = {Abbott, L. F. and Varela, J. A. and Sen, Kamal and Nelson, S. B.},
  date = {1997-01-10},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {275},
  number = {5297},
  pages = {221--224},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.275.5297.221},
  url = {https://www.science.org/doi/10.1126/science.275.5297.221},
  urldate = {2025-01-27},
  abstract = {Cortical neurons receive synaptic inputs from thousands of afferents that fire action potentials at rates ranging from less than 1 hertz to more than 200 hertz. Both the number of afferents and their large dynamic range can mask changes in the spatial and temporal pattern of synaptic activity, limiting the ability of a cortical neuron to respond to its inputs. Modeling work based on experimental measurements indicates that short-term depression of intracortical synapses provides a dynamic gain-control mechanism that allows equal percentage rate changes on rapidly and slowly firing afferents to produce equal postsynaptic responses. Unlike inhibitory and adaptive mechanisms that reduce responsiveness to all inputs, synaptic depression is input-specific, leading to a dramatic increase in the sensitivity of a neuron to subtle changes in the firing patterns of its afferents.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/B3BJZH8K/Abbott et al. - 1997 - Synaptic Depression and Cortical Gain Control.pdf}
}

@article{aertsenSpectroTemporalReceptiveField1981,
  title = {The {{Spectro-Temporal Receptive Field}}: {{A}} Functional Characteristic of Auditory Neurons},
  shorttitle = {The {{Spectro-Temporal Receptive Field}}},
  author = {Aertsen, A. M. H. J. and Johannesma, P. I. M.},
  date = {1981},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybern.},
  volume = {42},
  number = {2},
  pages = {133--143},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/BF00336731},
  url = {http://link.springer.com/10.1007/BF00336731},
  urldate = {2025-01-16},
  langid = {english},
  file = {/home/cristi/Zotero/storage/VZMK3Q7A/Aertsen and Johannesma - 1981 - The Spectro-Temporal Receptive Field A functional characteristic of auditory neurons.pdf}
}

@article{aertsenSpectrotemporalReceptiveFields1980,
  title = {Spectro-Temporal Receptive Fields of Auditory Neurons in the Grassfrog: {{I}}. {{Characterization}} of Tonal and Natural Stimuli},
  shorttitle = {Spectro-Temporal Receptive Fields of Auditory Neurons in the Grassfrog},
  author = {Aertsen, A. M. H. J. and Johannesma, P. I. M.},
  date = {1980-11},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybernetics},
  volume = {38},
  number = {4},
  pages = {223--234},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/BF00337015},
  url = {http://link.springer.com/10.1007/BF00337015},
  urldate = {2025-01-16},
  langid = {english},
  file = {/home/cristi/Zotero/storage/LV2Q6BEW/Aertsen and Johannesma - 1980 - Spectro-temporal receptive fields of auditory neurons in the grassfrog I. Characterization of tonal.pdf}
}

@article{aertsenSpectrotemporalReceptiveFields1980a,
  title = {Spectro-Temporal Receptive Fields of Auditory Neurons in the Grassfrog: {{II}}. {{Analysis}} of the Stimulus-Event Relation for Tonal Stimuli},
  shorttitle = {Spectro-Temporal Receptive Fields of Auditory Neurons in the Grassfrog},
  author = {Aertsen, A. M. H. J. and Johannesma, P. I. M. and Hermes, D. J.},
  date = {1980-11},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybernetics},
  volume = {38},
  number = {4},
  pages = {235--248},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/BF00337016},
  url = {http://link.springer.com/10.1007/BF00337016},
  urldate = {2025-01-16},
  langid = {english},
  file = {/home/cristi/Zotero/storage/DCFET4BV/Aertsen et al. - 1980 - Spectro-temporal receptive fields of auditory neurons in the grassfrog II. Analysis of the stimulus.pdf}
}

@article{ahrensNonlinearitiesContextualInfluences2008,
  title = {Nonlinearities and {{Contextual Influences}} in {{Auditory Cortical Responses Modeled}} with {{Multilinear Spectrotemporal Methods}}},
  author = {Ahrens, Misha B. and Linden, Jennifer F. and Sahani, Maneesh},
  date = {2008-02-20},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {28},
  number = {8},
  pages = {1929--1942},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3377-07.2008},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3377-07.2008},
  urldate = {2024-12-12},
  abstract = {The relationship between a sound and its neural representation in the auditory cortex remains elusive. Simple measures such as the frequency response area or frequency tuning curve provide little insight into the function of the auditory cortex in complex sound environments. Spectrotemporal receptive field (STRF) models, despite their descriptive potential, perform poorly when used to predict auditory cortical responses, showing that nonlinear features of cortical response functions, which are not captured by STRFs, are functionally important. We introduce a new approach to the description of auditory cortical responses, using multilinear modeling methods. These descriptions simultaneously account for several nonlinearities in the stimulus–response functions of auditory cortical neurons, including adaptation, spectral interactions, and nonlinear sensitivity to sound level. The models reveal multiple inseparabilities in cortical processing of time lag, frequency, and sound level, and suggest functional mechanisms by which auditory cortical neurons are sensitive to stimulus context. By explicitly modeling these contextual influences, the models are able to predict auditory cortical responses more accurately than are STRF models. In addition, they can explain some forms of stimulus dependence in STRFs that were previously poorly understood.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/CHX4BXXL/Ahrens et al. - 2008 - Nonlinearities and Contextual Influences in Audito.pdf}
}

@article{arlotSurveyCrossvalidationProcedures2010,
  title = {A Survey of Cross-Validation Procedures for Model Selection},
  author = {Arlot, Sylvain and Celisse, Alain},
  date = {2010-01-01},
  journaltitle = {Statistics Surveys},
  shortjournal = {Statist. Surv.},
  volume = {4},
  issn = {1935-7516},
  doi = {10.1214/09-SS054},
  url = {https://projecteuclid.org/journals/statistics-surveys/volume-4/issue-none/A-survey-of-cross-validation-procedures-for-model-selection/10.1214/09-SS054.full},
  urldate = {2025-05-19},
  issue = {none},
  file = {/home/cristi/Zotero/storage/YUYT4332/Arlot and Celisse - 2010 - A survey of cross-validation procedures for model selection.pdf}
}

@article{batesCrossValidationWhatDoes2024,
  title = {Cross-{{Validation}}: {{What Does It Estimate}} and {{How Well Does It Do It}}?},
  shorttitle = {Cross-{{Validation}}},
  author = {Bates, Stephen and Hastie, Trevor and Tibshirani, Robert},
  date = {2024-04-02},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {119},
  number = {546},
  pages = {1434--1445},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2023.2197686},
  url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2023.2197686},
  urldate = {2025-05-19},
  langid = {english},
  file = {/home/cristi/Zotero/storage/CIA9IR7D/Bates et al. - 2024 - Cross-Validation What Does It Estimate and How Well Does It Do It.pdf}
}

@article{bizleyFunctionalOrganizationFerret2005,
  title = {Functional {{Organization}} of {{Ferret Auditory Cortex}}},
  author = {Bizley, Jennifer K. and Nodal, Fernando R. and Nelken, Israel and King, Andrew J.},
  date = {2005-10-01},
  journaltitle = {Cerebral Cortex},
  volume = {15},
  number = {10},
  pages = {1637--1653},
  issn = {1460-2199, 1047-3211},
  doi = {10.1093/cercor/bhi042},
  url = {http://academic.oup.com/cercor/article/15/10/1637/397009/Functional-Organization-of-Ferret-Auditory-Cortex},
  urldate = {2025-02-26},
  langid = {english},
  file = {/home/cristi/Zotero/storage/GR2AFFGZ/Bizley et al. - 2005 - Functional Organization of Ferret Auditory Cortex.pdf}
}

@article{carandiniNormalizationCanonicalNeural2012,
  title = {Normalization as a Canonical Neural Computation},
  author = {Carandini, Matteo and Heeger, David J.},
  date = {2012-01},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {13},
  number = {1},
  pages = {51--62},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3136},
  url = {https://www.nature.com/articles/nrn3136},
  urldate = {2025-01-27},
  langid = {english},
  file = {/home/cristi/Zotero/storage/FZUUFPZU/Carandini and Heeger - 2012 - Normalization as a canonical neural computation.pdf;/home/cristi/Zotero/storage/S3BVCZRR/nrn3136.pdf}
}

@article{davidPredictingNeuronalResponses2005,
  title = {Predicting Neuronal Responses during Natural Vision},
  author = {David, Stephen V. and Gallant, Jack L.},
  date = {2005-01},
  journaltitle = {Network: Computation in Neural Systems},
  shortjournal = {Network: Computation in Neural Systems},
  volume = {16},
  number = {2--3},
  pages = {239--260},
  issn = {0954-898X, 1361-6536},
  doi = {10.1080/09548980500464030},
  url = {https://www.tandfonline.com/doi/full/10.1080/09548980500464030},
  urldate = {2025-02-17},
  langid = {english},
  file = {/home/cristi/Zotero/storage/N27PMM55/David and Gallant - 2005 - Predicting neuronal responses during natural vision.pdf}
}

@article{deboerCochlearEncodingPotentialities1978,
  title = {On Cochlear Encoding: {{Potentialities}} and Limitations of the Reverse-Correlation Technique},
  shorttitle = {On Cochlear Encoding},
  author = {De Boer, E. and De Jongh, H. R.},
  date = {1978-01-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {63},
  number = {1},
  pages = {115--135},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.381704},
  url = {https://pubs.aip.org/jasa/article/63/1/115/690700/On-cochlear-encoding-Potentialities-and},
  urldate = {2025-05-21},
  abstract = {This paper presents a description of the interrelation between two major properties of the responses recordable from auditory nerve fibers: frequency\hphantom{,}selectivity and partial\hphantom{,}synchrony between stimulus and response. In the course of this work the influence of nonlinearity on the cochlear encoding process can be assessed. The theory of the reverse-correlation\hphantom{,}technique is derived in a most general way. It is based on a model in which a filter—assumed to be linear—is followed by a stochastic pulse generator—the probability of producing an output pulse being an instantaneous but nonlinear function of its input signal. Insofar as such a model represents stimulus transformations in a primary auditory neuron, the technique can be applied to the responses recorded from an auditory nerve fiber. Several illustrative examples of experimental reverse-correlation functions−abbreviated: revcor\hphantom{,}functions—are presented and discussed. These functions have the general character of impulse responses of sharp bandpass filters. They show very little phase modulation. For noise stimuli of up to 70 dB per third octave the revcor functions are almost invariant. Above that level some (but not all) of the revcor functions show a loss of frequency selectivity. If a nerve fiber can be contacted for a sufficiently long time, it is possible to compare the response with that of a model filter, in which the revcor function of that fiber is substituted as its impulse response. The output signal of the model filter is shown to be a very good predictor of the firing probability of the fiber under study. This property is demonstrated for noise as well as for tone stimuli. There is surprisingly little evidence of nonlinear filtering in these results. This so-called simulation method can also be applied when the stimulus is switched on and off. The results show, apart from effects due to filtering, clear manifestations of fast adaptation. Again, the filtering appears to be independent of the latter effect. It is concluded that for wide-band noise and single-tone signals the firing probability is predominantly controlled by a linearly filtered version of the acoustical stimulus; this constitutes the principle of specific\hphantom{,}coding. The conspicuous absence of nonlinear effects in the results can partly be explained in terms of the response properties of a class of networks in which sharp filtering occurs after the generation of nonlinear distortion products. It can then be predicted that this property will hold only for wide-band and tonal stimuli. That our results show so little evidence of cochlear distortion appears to be a property of signal transformations and is not due to linearization tendencies of the experimental method.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/X58JIQK3/De Boer and De Jongh - 1978 - On cochlear encoding Potentialities and limitations of the reverse-correlation technique.pdf}
}

@article{deboerTriggeredCorrelation1968,
  title = {Triggered {{Correlation}}},
  author = {De Boer, Egbert and Kuyper, Paul},
  date = {1968-07},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  shortjournal = {IEEE Trans. Biomed. Eng.},
  volume = {BME-15},
  number = {3},
  pages = {169--179},
  issn = {0018-9294},
  doi = {10.1109/TBME.1968.4502561},
  url = {http://ieeexplore.ieee.org/document/4502561/},
  urldate = {2025-05-13},
  file = {/home/cristi/Zotero/storage/SN5F6H7D/De Boer and Kuyper - 1968 - Triggered Correlation.pdf}
}

@article{giovannucciCaImAnOpenSource2019,
  title = {{{CaImAn}} an Open Source Tool for Scalable Calcium Imaging Data Analysis},
  author = {Giovannucci, Andrea and Friedrich, Johannes and Gunn, Pat and Kalfon, Jérémie and Brown, Brandon L and Koay, Sue Ann and Taxidis, Jiannis and Najafi, Farzaneh and Gauthier, Jeffrey L and Zhou, Pengcheng and Khakh, Baljit S and Tank, David W and Chklovskii, Dmitri B and Pnevmatikakis, Eftychios A},
  date = {2019-01-17},
  journaltitle = {eLife},
  volume = {8},
  pages = {e38173},
  issn = {2050-084X},
  doi = {10.7554/eLife.38173},
  url = {https://elifesciences.org/articles/38173},
  urldate = {2025-03-17},
  abstract = {Advances in fluorescence microscopy enable monitoring larger brain areas in-vivo with finer time resolution. The resulting data rates require reproducible analysis pipelines that are reliable, fully automated, and scalable to datasets generated over the course of months. We present CaImAn, an open-source library for calcium imaging data analysis. CaImAn provides automatic and scalable methods to address problems common to pre-processing, including motion correction, neural activity identification, and registration across different sessions of data collection. It does this while requiring minimal user intervention, with good scalability on computers ranging from laptops to high-performance computing clusters. CaImAn is suitable for two-photon and one-photon imaging, and also enables real-time analysis on streaming data. To benchmark the performance of CaImAn we collected and combined a corpus of manual annotations from multiple labelers on nine mouse two-photon datasets. We demonstrate that CaImAn achieves near-human performance in detecting locations of active neurons.           ,              The human brain contains billions of cells called neurons that rapidly carry information from one part of the brain to another. Progress in medical research and healthcare is hindered by the difficulty in understanding precisely which neurons are active at any given time. New brain imaging techniques and genetic tools allow researchers to track the activity of thousands of neurons in living animals over many months. However, these experiments produce large volumes of data that researchers currently have to analyze manually, which can take a long time and generate irreproducible results.             There is a need to develop new computational tools to analyze such data. The new tools should be able to operate on standard computers rather than just specialist equipment as this would limit the use of the solutions to particularly well-funded research teams. Ideally, the tools should also be able to operate in real-time as several experimental and therapeutic scenarios, like the control of robotic limbs, require this. To address this need, Giovannucci et al. developed a new software package called CaImAn to analyze brain images on a large scale.             Firstly, the team developed algorithms that are suitable to analyze large sets of data on laptops and other standard computing equipment. These algorithms were then adapted to operate online in real-time. To test how well the new software performs against manual analysis by human researchers, Giovannucci et al. asked several trained human annotators to identify active neurons that were round or donut-shaped in several sets of imaging data from mouse brains. Each set of data was independently analyzed by three or four researchers who then discussed any neurons they disagreed on to generate a ‘consensus annotation’. Giovannucci et al. then used CaImAn to analyze the same sets of data and compared the results to the consensus annotations. This demonstrated that CaImAn is nearly as good as human researchers at identifying active neurons in brain images.             CaImAn provides a quicker method to analyze large sets of brain imaging data and is currently used by over a hundred laboratories across the world. The software is open source, meaning that it is freely-available and that users are encouraged to customize it and collaborate with other users to develop it further.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/K9866SNT/Giovannucci et al. - 2019 - CaImAn an open source tool for scalable calcium imaging data analysis.pdf}
}

@article{grienbergerImagingCalciumNeurons2012,
  title = {Imaging {{Calcium}} in {{Neurons}}},
  author = {Grienberger, Christine and Konnerth, Arthur},
  date = {2012-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {73},
  number = {5},
  pages = {862--885},
  issn = {08966273},
  doi = {10.1016/j.neuron.2012.02.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312001729},
  urldate = {2025-02-17},
  langid = {english},
  file = {/home/cristi/Zotero/storage/9U59NCXZ/Grienberger and Konnerth - 2012 - Imaging Calcium in Neurons.pdf}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {08936080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
  urldate = {2025-05-11},
  langid = {english},
  file = {/home/cristi/Zotero/storage/NF45PU4Q/Hornik et al. - 1989 - Multilayer feedforward networks are universal approximators.pdf}
}

@article{issaMultiscaleOpticalCa22014,
  title = {Multiscale {{Optical Ca2}}+ {{Imaging}} of {{Tonal Organization}} in {{Mouse Auditory Cortex}}},
  author = {Issa, John~B. and Haeffele, Benjamin~D. and Agarwal, Amit and Bergles, Dwight~E. and Young, Eric~D. and Yue, David~T.},
  date = {2014-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {83},
  number = {4},
  pages = {944--959},
  issn = {08966273},
  doi = {10.1016/j.neuron.2014.07.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662731400590X},
  urldate = {2025-02-28},
  langid = {english},
  file = {/home/cristi/Zotero/storage/4ASTQFG8/Issa et al. - 2014 - Multiscale Optical Ca2+ Imaging of Tonal Organization in Mouse Auditory Cortex.pdf}
}

@article{josephDischargePatternsSingle1967,
  title = {Discharge Patterns of Single Fibers in the Cat's Auditory Nerve},
  author = {Joseph, Alexander},
  date = {1967-05},
  journaltitle = {Journal of Communication Disorders},
  shortjournal = {Journal of Communication Disorders},
  volume = {1},
  number = {1},
  pages = {104--105},
  issn = {00219924},
  doi = {10.1016/0021-9924(67)90048-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0021992467900482},
  urldate = {2025-05-21},
  langid = {english},
  file = {/home/cristi/Zotero/storage/AU6HWVVY/Joseph - 1967 - Discharge patterns of single fibers in the cat's auditory nerve.pdf}
}

@article{keshishianEstimatingInterpretingNonlinear2020,
  title = {Estimating and Interpreting Nonlinear Receptive Field of Sensory Neural Responses with Deep Neural Network Models},
  author = {Keshishian, Menoua and Akbari, Hassan and Khalighinejad, Bahar and Herrero, Jose L and Mehta, Ashesh D and Mesgarani, Nima},
  date = {2020-06-26},
  journaltitle = {eLife},
  volume = {9},
  pages = {e53445},
  issn = {2050-084X},
  doi = {10.7554/eLife.53445},
  url = {https://elifesciences.org/articles/53445},
  urldate = {2024-12-19},
  abstract = {Our understanding of nonlinear stimulus transformations by neural circuits is hindered by the lack of comprehensive yet interpretable computational modeling frameworks. Here, we propose a data-driven approach based on deep neural networks to directly model arbitrarily nonlinear stimulus-response mappings. Reformulating the exact function of a trained neural network as a collection of stimulus-dependent linear functions enables a locally linear receptive field interpretation of the neural network. Predicting the neural responses recorded invasively from the auditory cortex of neurosurgical patients as they listened to speech, this approach significantly improves the prediction accuracy of auditory cortical responses, particularly in nonprimary areas. Moreover, interpreting the functions learned by neural networks uncovered three distinct types of nonlinear transformations of speech that varied considerably from primary to nonprimary auditory regions. The ability of this framework to capture arbitrary stimulus-response mappings while maintaining model interpretability leads to a better understanding of cortical processing of sensory signals.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/KTBBSF6W/Keshishian et al. - 2020 - Estimating and interpreting nonlinear receptive fi.pdf}
}

@article{kleinStimulusinvariantProcessingSpectrotemporal2006,
  title = {Stimulus-Invariant Processing and Spectrotemporal Reverse Correlation in Primary Auditory Cortex},
  author = {Klein, David J. and Simon, Jonathan Z. and Depireux, Didier A. and Shamma, Shihab A.},
  date = {2006-04},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {20},
  number = {2},
  pages = {111--136},
  issn = {0929-5313, 1573-6873},
  doi = {10.1007/s10827-005-3589-4},
  url = {http://link.springer.com/10.1007/s10827-005-3589-4},
  urldate = {2025-01-13},
  langid = {english},
  file = {/home/cristi/Zotero/storage/TM3PBEQB/Klein et al. - 2006 - Stimulus-invariant processing and spectrotemporal reverse correlation in primary auditory cortex.pdf}
}

@article{krizhevskyImageNetClassificationDeep2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  number = {6},
  pages = {84--90},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3065386},
  url = {https://dl.acm.org/doi/10.1145/3065386},
  urldate = {2025-05-29},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/8I2CXRXC/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional neural networks.pdf}
}

@article{lindebergIdealizedComputationalModels2015,
  title = {Idealized {{Computational Models}} for {{Auditory Receptive Fields}}},
  author = {Lindeberg, Tony and Friberg, Anders},
  editor = {Kotz, Sonja},
  date = {2015-03-30},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {10},
  number = {3},
  pages = {e0119032},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0119032},
  url = {https://dx.plos.org/10.1371/journal.pone.0119032},
  urldate = {2025-05-13},
  langid = {english},
  file = {/home/cristi/Zotero/storage/NDCVQCZ8/Lindeberg and Friberg - 2015 - Idealized Computational Models for Auditory Receptive Fields.pdf}
}

@article{lindenSpectrotemporalStructureReceptive2003,
  title = {Spectrotemporal {{Structure}} of {{Receptive Fields}} in {{Areas AI}} and {{AAF}} of {{Mouse Auditory Cortex}}},
  author = {Linden, Jennifer F. and Liu, Robert C. and Sahani, Maneesh and Schreiner, Christoph E. and Merzenich, Michael M.},
  date = {2003-10},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {Journal of Neurophysiology},
  volume = {90},
  number = {4},
  pages = {2660--2675},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00751.2002},
  url = {https://www.physiology.org/doi/10.1152/jn.00751.2002},
  urldate = {2025-02-28},
  abstract = {The mouse is a promising model system for auditory cortex research because of the powerful genetic tools available for manipulating its neural circuitry. Previous studies have identified two tonotopic auditory areas in the mouse—primary auditory cortex (AI) and anterior auditory field (AAF)— but auditory receptive fields in these areas have not yet been described. To establish a foundation for investigating auditory cortical circuitry and plasticity in the mouse, we characterized receptive-field structure in AI and AAF of anesthetized mice using spectrally complex and temporally dynamic stimuli as well as simple tonal stimuli. Spectrotemporal receptive fields (STRFs) were derived from extracellularly recorded responses to complex stimuli, and frequency-intensity tuning curves were constructed from responses to simple tonal stimuli. Both analyses revealed temporal differences between AI and AAF responses: peak latencies and receptive-field durations for STRFs and first-spike latencies for responses to tone bursts were significantly longer in AI than in AAF. Spectral properties of AI and AAF receptive fields were more similar, although STRF bandwidths were slightly broader in AI than in AAF. Finally, in both AI and AAF, a substantial minority of STRFs were spectrotemporally inseparable. The spectrotemporal interaction typically appeared in the form of clearly disjoint excitatory and inhibitory subfields or an obvious spectrotemporal slant in the STRF. These data provide the first detailed description of auditory receptive fields in the mouse and suggest that although neurons in areas AI and AAF share many response characteristics, area AAF may be specialized for faster temporal processing.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/RVN8P4VU/Linden et al. - 2003 - Spectrotemporal Structure of Receptive Fields in Areas AI and AAF of Mouse Auditory Cortex.pdf}
}

@article{liSurveyConvolutionalNeural2022,
  title = {A {{Survey}} of {{Convolutional Neural Networks}}: {{Analysis}}, {{Applications}}, and {{Prospects}}},
  shorttitle = {A {{Survey}} of {{Convolutional Neural Networks}}},
  author = {Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  date = {2022-12},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {33},
  number = {12},
  pages = {6999--7019},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2021.3084827},
  url = {https://ieeexplore.ieee.org/document/9451544/},
  urldate = {2025-05-29},
  file = {/home/cristi/Zotero/storage/DRAJMGQX/Li et al. - 2022 - A Survey of Convolutional Neural Networks Analysis, Applications, and Prospects.pdf}
}

@article{machensLinearityCorticalReceptive2004,
  title = {Linearity of {{Cortical Receptive Fields Measured}} with {{Natural Sounds}}},
  author = {Machens, Christian K. and Wehr, Michael S. and Zador, Anthony M.},
  date = {2004-02-04},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {24},
  number = {5},
  pages = {1089--1100},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.4445-03.2004},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.4445-03.2004},
  urldate = {2025-05-05},
  abstract = {How do cortical neurons represent the acoustic environment? This question is often addressed by probing with simple stimuli such as clicks or tone pips. Such stimuli have the advantage of yielding easily interpreted answers, but have the disadvantage that they may fail to uncover complex or higher-order neuronal response properties. Here, we adopt an alternative approach, probing neuronal responses with complex acoustic stimuli, including animal vocalizations. We used               in vivo               whole-cell methods in the rat auditory cortex to record subthreshold membrane potential fluctuations elicited by these stimuli. Most neurons responded robustly and reliably to the complex stimuli in our ensemble. Using regularization techniques, we estimated the linear component, the spectrotemporal receptive field (STRF), of the transformation from the sound (as represented by its time-varying spectrogram) to the membrane potential of the neuron. We find that the STRF has a rich dynamical structure, including excitatory regions positioned in general accord with the prediction of the classical tuning curve. However, whereas the STRF successfully predicts the responses to some of the natural stimuli, it surprisingly fails completely to predict the responses to others; on average, only 11\% of the response power could be predicted by the STRF. Therefore, most of the response of the neuron cannot be predicted by the linear component, although the response is deterministically related to the stimulus. Analysis of the systematic errors of the STRF model shows that this failure cannot be attributed to simple nonlinearities such as adaptation to mean intensity, rectification, or saturation. Rather, the highly nonlinear response properties of auditory cortical neurons must be attributable to nonlinear interactions between sound frequencies and time-varying properties of the neural encoder.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/2UUFI2KC/Machens et al. - 2004 - Linearity of Cortical Receptive Fields Measured with Natural Sounds.pdf}
}

@incollection{malmiercaAuditorySystem2012,
  title = {Auditory {{System}}},
  booktitle = {The {{Mouse Nervous System}}},
  author = {Malmierca, Manuel S. and Ryugo, David K.},
  date = {2012},
  pages = {607--645},
  publisher = {Elsevier},
  doi = {10.1016/B978-0-12-369497-3.10024-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B978012369497310024X},
  urldate = {2025-03-01},
  isbn = {978-0-12-369497-3},
  langid = {english},
  file = {/home/cristi/Zotero/storage/CF53PCPJ/Malmierca and Ryugo - 2012 - Auditory System.pdf}
}

@article{meyerModelsNeuronalStimulusResponse2017,
  title = {Models of {{Neuronal Stimulus-Response Functions}}: {{Elaboration}}, {{Estimation}}, and {{Evaluation}}},
  shorttitle = {Models of {{Neuronal Stimulus-Response Functions}}},
  author = {Meyer, Arne F. and Williamson, Ross S. and Linden, Jennifer F. and Sahani, Maneesh},
  date = {2017-01-12},
  journaltitle = {Frontiers in Systems Neuroscience},
  shortjournal = {Front. Syst. Neurosci.},
  volume = {10},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2016.00109},
  url = {http://journal.frontiersin.org/article/10.3389/fnsys.2016.00109/full},
  urldate = {2025-02-23},
  file = {/home/cristi/Zotero/storage/QMY7SXYD/Meyer et al. - 2017 - Models of Neuronal Stimulus-Response Functions Elaboration, Estimation, and Evaluation.pdf}
}

@article{parkReceptiveFieldInference2011,
  title = {Receptive {{Field Inference}} with {{Localized Priors}}},
  author = {Park, Mijung and Pillow, Jonathan W.},
  editor = {Sporns, Olaf},
  date = {2011-10-27},
  journaltitle = {PLoS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {7},
  number = {10},
  pages = {e1002219},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002219},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1002219},
  urldate = {2025-05-13},
  langid = {english},
  file = {/home/cristi/Zotero/storage/VFGFU2C3/Park and Pillow - 2011 - Receptive Field Inference with Localized Priors.pdf}
}

@article{petersenOptimalApproximationPiecewise2018,
  title = {Optimal Approximation of Piecewise Smooth Functions Using Deep {{ReLU}} Neural Networks},
  author = {Petersen, Philipp and Voigtlaender, Felix},
  date = {2018-12},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {108},
  pages = {296--330},
  issn = {08936080},
  doi = {10.1016/j.neunet.2018.08.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608018302454},
  urldate = {2025-05-11},
  langid = {english},
  file = {/home/cristi/Zotero/storage/7CTZXEFA/Petersen and Voigtlaender - 2018 - Optimal approximation of piecewise smooth functions using deep ReLU neural networks.pdf}
}

@article{pnevmatikakisSimultaneousDenoisingDeconvolution2016,
  title = {Simultaneous {{Denoising}}, {{Deconvolution}}, and {{Demixing}} of {{Calcium Imaging Data}}},
  author = {Pnevmatikakis, Eftychios~A. and Soudry, Daniel and Gao, Yuanjun and Machado, Timothy A. and Merel, Josh and Pfau, David and Reardon, Thomas and Mu, Yu and Lacefield, Clay and Yang, Weijian and Ahrens, Misha and Bruno, Randy and Jessell, Thomas M. and Peterka, Darcy~S. and Yuste, Rafael and Paninski, Liam},
  date = {2016-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {89},
  number = {2},
  pages = {285--299},
  issn = {08966273},
  doi = {10.1016/j.neuron.2015.11.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627315010843},
  urldate = {2025-03-06},
  langid = {english},
  file = {/home/cristi/Zotero/storage/NK8EK4VY/Pnevmatikakis et al. - 2016 - Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data.pdf}
}

@article{realeTonotopicOrganizationAuditory1980,
  title = {Tonotopic Organization in Auditory Cortex of the Cat},
  author = {Reale, Richard A. and Imig, Thomas J.},
  date = {1980-07-15},
  journaltitle = {Journal of Comparative Neurology},
  shortjournal = {J of Comparative Neurology},
  volume = {192},
  number = {2},
  pages = {265--291},
  issn = {0021-9967, 1096-9861},
  doi = {10.1002/cne.901920207},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/cne.901920207},
  urldate = {2025-02-23},
  abstract = {Abstract             Microelectrode mapping techniques were employed in the cat's auditory cortex to relate the best frequencies of a large population of neurons with their spatial loci. Based upon the best‐frequency distribution, the auditory region was divided into four complete and orderly tonotopic representations and a surrounding belt of cortex in which the tonotopic organization was more complex. The four auditory fields occupy a crescent‐shaped band of tissue which comprises portions of both the exposed gyral surfaces and sulcal banks of the ectosylvian cortex. The anterior auditory field (A) is situated most rostrally upon the anterior ectosylvian gyrus. It extends upon the ventral bank of the suprasylvian sulcus and upon the banks of the anterior ectosylvian sulcus. Adjoining field A caudally is the primary auditory field (AI), which extends across the middle ectosylvian gyrus and portions of both banks of the posterior ectosylvian sulcus. The representations of the highest best frequencies in fields A and AI are contiguous. Caudal and ventral to AI are located the posterior (P) and ventroposterior (VP) auditory fields. They lie mainly upon the caudal bank of the posterior ectosylvian sulcus but also extend upon the rostral bank and upon the posterior ectosylvian gyrus. The low best‐frequency representations of fields AI and P are contiguous, whereas the low best‐frequency representation of field VP lies near the ventral end of the posterior ectosylvian sulcus. Fields P and VP are joined along their middle and high best‐frequency representations. Within each auditory field isofrequency lines defined by the spatial loci of neurons with similar best frequencies are oriented orthogonal to the low‐to‐high best‐frequency gradients.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/YPNXQJIS/Reale and Imig - 1980 - Tonotopic organization in auditory cortex of the cat.pdf}
}

@article{saenzTonotopicMappingHuman2014,
  title = {Tonotopic Mapping of Human Auditory Cortex},
  author = {Saenz, Melissa and Langers, Dave R.M.},
  date = {2014-01},
  journaltitle = {Hearing Research},
  shortjournal = {Hearing Research},
  volume = {307},
  pages = {42--52},
  issn = {03785955},
  doi = {10.1016/j.heares.2013.07.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0378595513001871},
  urldate = {2025-02-26},
  langid = {english},
  file = {/home/cristi/Zotero/storage/VY4D55HV/Saenz and Langers - 2014 - Tonotopic mapping of human auditory cortex.pdf}
}

@inproceedings{sahaniEvidenceOptimizationTechniques2002,
  title = {Evidence Optimization Techniques for Estimating Stimulus-Response Functions},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Sahani, Maneesh and Linden, Jennifer},
  editor = {Becker, S. and Thrun, S. and Obermayer, K.},
  date = {2002},
  volume = {15},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper_files/paper/2002/file/229754d7799160502a143a72f6789927-Paper.pdf},
  file = {/home/cristi/Zotero/storage/ICSSZEAL/Sahani and Linden - 2002 - Evidence optimization techniques for estimating stimulus-response functions.pdf}
}

@inreference{SpectrotemporalReceptiveField2023,
  title = {Spectro-Temporal Receptive Field},
  booktitle = {Wikipedia},
  date = {2023-02-24T03:29:00Z},
  url = {https://en.wikipedia.org/w/index.php?title=Spectro-temporal_receptive_field&oldid=1141251249},
  urldate = {2025-03-12},
  abstract = {The spectro-temporal receptive field or spatio-temporal receptive field (STRF) of a neuron represents which types of stimuli excite or inhibit that neuron.  "Spectro-temporal" refers most commonly to audition, where the neuron's response depends on frequency versus time, while "spatio-temporal" refers to vision, where the neuron's response depends on spatial location versus time. Thus they are not exactly the same concept, but both are referred to as STRF and serve a similar role in the analysis of neural responses. If linearity is assumed, the neuron can be modeled as having a time-varying firing rate equal to the convolution of the stimulus with the STRF.},
  langid = {english},
  annotation = {Page Version ID: 1141251249},
  file = {/home/cristi/Zotero/storage/LH5UPDKI/Spectro-temporal_receptive_field.html}
}

@online{Stats,
  title = {Stats},
  url = {https://prezenta.roaep.ro/prezidentiale18052025/presence/stats},
  urldate = {2025-05-17},
  abstract = {Prezidentiale, 18 Mai 2025, turul 2. Rezultate electorale in timp real. Date de pe tabletele din sectiile de votare si procesele verbale. Istoric ale proceselor electorale anterioare si posibilitate de comparare.},
  organization = {Prezenta la vot},
  file = {/home/cristi/Zotero/storage/46A8ZTB7/stats.html}
}

@article{stoneCrossValidatoryChoiceAssessment1974,
  title = {Cross-{{Validatory Choice}} and {{Assessment}} of {{Statistical Predictions}}},
  author = {Stone, M.},
  date = {1974-01-01},
  journaltitle = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {36},
  number = {2},
  pages = {111--133},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.2517-6161.1974.tb00994.x},
  url = {https://academic.oup.com/jrsssb/article/36/2/111/7027414},
  urldate = {2025-05-19},
  abstract = {Summary             A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/WT4ZKEU5/Stone - 1974 - Cross-Validatory Choice and Assessment of Statistical Predictions.pdf}
}

@article{syedaFacemapFrameworkModeling2024,
  title = {Facemap: A Framework for Modeling Neural Activity Based on Orofacial Tracking},
  shorttitle = {Facemap},
  author = {Syeda, Atika and Zhong, Lin and Tung, Renee and Long, Will and Pachitariu, Marius and Stringer, Carsen},
  date = {2024-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {27},
  number = {1},
  pages = {187--195},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-023-01490-6},
  url = {https://www.nature.com/articles/s41593-023-01490-6},
  urldate = {2025-02-28},
  abstract = {Abstract             Recent studies in mice have shown that orofacial behaviors drive a large fraction of neural activity across the brain. To understand the nature and function of these signals, we need better computational models to characterize the behaviors and relate them to neural activity. Here we developed Facemap, a framework consisting of a keypoint tracker and a deep neural network encoder for predicting neural activity. Our algorithm for tracking mouse orofacial behaviors was more accurate than existing pose estimation tools, while the processing speed was several times faster, making it a powerful tool for real-time experimental interventions. The Facemap tracker was easy to adapt to data from new labs, requiring as few as 10 annotated frames for near-optimal performance. We used the keypoints as inputs to a deep neural network which predicts the activity of \textasciitilde 50,000 simultaneously-recorded neurons and, in visual cortex, we doubled the amount of explained variance compared to previous methods. Using this model, we found that the neuronal activity clusters that were well predicted from behavior were more spatially spread out across cortex. We also found that the deep behavioral features from the model had stereotypical, sequential dynamics that were not reversible in time. In summary, Facemap provides a stepping stone toward understanding the function of the brain-wide neural signals and their relation to behavior.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/G96SG2RH/Syeda et al. - 2024 - Facemap a framework for modeling neural activity based on orofacial tracking.pdf}
}

@article{theunissenEstimatingSpatiotemporalReceptive2001,
  title = {Estimating Spatio-Temporal Receptive Fields of Auditory and Visual Neurons from Their Responses to Natural Stimuli},
  author = {Theunissen, F.E. and David, S.V. and Singh, N.C. and Hsu, A. and Vinje, W.E. and Gallant, J.L.},
  date = {2001-01},
  journaltitle = {Network: Computation in Neural Systems},
  shortjournal = {Network: Computation in Neural Systems},
  volume = {12},
  number = {3},
  pages = {289--316},
  issn = {0954-898X, 1361-6536},
  doi = {10.1080/net.12.3.289.316},
  url = {https://www.tandfonline.com/doi/full/10.1080/net.12.3.289.316},
  urldate = {2025-01-16},
  langid = {english},
  file = {/home/cristi/Zotero/storage/FKGBNTM9/Theunissen et al. - 2001 - Estimating spatio-temporal receptive fields of auditory and visual neurons from their responses to n.pdf}
}

@article{theunissenSpectralTemporalReceptiveFields2000,
  title = {Spectral-{{Temporal Receptive Fields}} of {{Nonlinear Auditory Neurons Obtained Using Natural Sounds}}},
  author = {Theunissen, Frédéric E. and Sen, Kamal and Doupe, Allison J.},
  date = {2000-03-15},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {20},
  number = {6},
  pages = {2315--2331},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.20-06-02315.2000},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.20-06-02315.2000},
  urldate = {2025-05-05},
  abstract = {The stimulus–response function of many visual and auditory neurons has been described by a spatial-temporal receptive field (STRF), a linear model that for mathematical reasons has until recently been estimated with the reverse correlation method, using simple stimulus ensembles such as white noise. Such stimuli, however, often do not effectively activate high-level sensory neurons, which may be optimized to analyze natural sounds and images. We show that it is possible to overcome the simple-stimulus limitation and then use this approach to calculate the STRFs of avian auditory forebrain neurons from an ensemble of birdsongs. We find that in many cases the STRFs derived using natural sounds are strikingly different from the STRFs that we obtained using an ensemble of random tone pips. When we compare these two models by assessing their predictions of neural response to the actual data, we find that the STRFs obtained from natural sounds are superior. Our results show that the STRF model is an incomplete description of response properties of nonlinear auditory neurons, but that linear receptive fields are still useful models for understanding higher level sensory processing, as long as the STRFs are estimated from the responses to relevant complex stimuli.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/D3S9JUGU/Theunissen et al. - 2000 - Spectral-Temporal Receptive Fields of Nonlinear Auditory Neurons Obtained Using Natural Sounds.pdf}
}

@article{verdaasdonkEndingRulesWidefield2014,
  title = {\textsc{B} Ending the {{Rules}}: {{Widefield Microscopy}} and the {{Abbe Limit}} of {{Resolution}}},
  author = {Verdaasdonk, Jolien S. and Stephens, Andrew D. and Haase, Julian and Bloom, Kerry},
  date = {2014-02},
  journaltitle = {Journal of Cellular Physiology},
  shortjournal = {Journal Cellular Physiology},
  volume = {229},
  number = {2},
  pages = {132--138},
  issn = {0021-9541, 1097-4652},
  doi = {10.1002/jcp.24439},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/jcp.24439},
  urldate = {2025-03-23},
  abstract = {Abstract                                           One of the most fundamental concepts of microscopy is that of resolution–the ability to clearly distinguish two objects as separate. Recent advances such as structured illumination microscopy (SIM) and point localization techniques including photoactivated localization microscopy (PALM), and stochastic optical reconstruction microscopy (STORM) strive to overcome the inherent limits of resolution of the modern light microscope. These techniques, however, are not always feasible or optimal for live cell imaging. Thus, in this review, we explore three techniques for extracting high resolution data from images acquired on a widefield microscope–deconvolution, model convolution, and Gaussian fitting. Deconvolution is a powerful tool for restoring a blurred image using knowledge of the point spread function (PSF) describing the blurring of light by the microscope, although care must be taken to ensure accuracy of subsequent quantitative analysis. The process of model convolution also requires knowledge of the PSF to blur a simulated image which can then be compared to the experimentally acquired data to reach conclusions regarding its geometry and fluorophore distribution. Gaussian fitting is the basis for point localization microscopy, and can also be applied to tracking spot motion over time or measuring spot shape and size. All together, these three methods serve as powerful tools for high‐resolution imaging using widefield microscopy. J. Cell. Physiol. 229: 132–138, 2014. © 2013 Wiley Periodicals, Inc.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/33YZA893/Verdaasdonk et al. - 2014 - B ending the Rules Widefield Microscopy and the Abbe.pdf}
}

@article{vogtPredictingNeuralActivity2024,
  title = {Predicting Neural Activity from Facial Expressions},
  author = {Vogt, Nina},
  date = {2024-01},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {21},
  number = {1},
  pages = {9--9},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/s41592-023-02154-w},
  url = {https://www.nature.com/articles/s41592-023-02154-w},
  urldate = {2025-02-28},
  langid = {english},
  file = {/home/cristi/Zotero/storage/TYNPAPCB/Vogt - 2024 - Predicting neural activity from facial expressions.pdf}
}

@article{weiComparisonNeuronalPopulation2020,
  title = {A Comparison of Neuronal Population Dynamics Measured with Calcium Imaging and Electrophysiology},
  author = {Wei, Ziqiang and Lin, Bei-Jung and Chen, Tsai-Wen and Daie, Kayvon and Svoboda, Karel and Druckmann, Shaul},
  editor = {Gutkin, Boris S.},
  date = {2020-09-15},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {16},
  number = {9},
  pages = {e1008198},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008198},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1008198},
  urldate = {2025-05-15},
  langid = {english},
  file = {/home/cristi/Zotero/storage/QKGAJCXV/Wei et al. - 2020 - A comparison of neuronal population dynamics measured with calcium imaging and electrophysiology.pdf}
}

@article{wessingerTonotopyHumanAuditory1997,
  title = {Tonotopy in Human Auditory Cortex Examined with Functional Magnetic Resonance Imaging},
  author = {Wessinger, C. Mark and Buonocore, Michael H. and Kussmaul, Clif L. and Mangun, George R.},
  date = {1997},
  journaltitle = {Human Brain Mapping},
  shortjournal = {Hum. Brain Mapp.},
  volume = {5},
  number = {1},
  pages = {18--25},
  issn = {10659471},
  doi = {10.1002/(SICI)1097-0193(1997)5:1<18::AID-HBM3>3.0.CO;2-Q},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0193(1997)5:1<18::AID-HBM3>3.0.CO;2-Q},
  urldate = {2025-02-26},
  langid = {english},
  file = {/home/cristi/Zotero/storage/ZEP8UXL8/Wessinger et al. - 1997 - Tonotopy in human auditory cortex examined with functional magnetic resonance imaging.pdf}
}

@article{yangAuditoryRepresentationsAcoustic1992,
  title = {Auditory Representations of Acoustic Signals},
  author = {Yang, X. and Wang, K. and Shamma, S.A.},
  date = {1992-03},
  journaltitle = {IEEE Transactions on Information Theory},
  shortjournal = {IEEE Trans. Inform. Theory},
  volume = {38},
  number = {2},
  pages = {824--839},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/18.119739},
  url = {http://ieeexplore.ieee.org/document/119739/},
  urldate = {2025-02-14},
  file = {/home/cristi/Zotero/storage/M5VYFUMI/Yang et al. - 1992 - Auditory representations of acoustic signals.pdf}
}

@incollection{zeilerVisualizingUnderstandingConvolutional2014,
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2014},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  date = {2014},
  volume = {8689},
  pages = {818--833},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-10590-1_53},
  url = {http://link.springer.com/10.1007/978-3-319-10590-1_53},
  urldate = {2025-05-29},
  isbn = {978-3-319-10589-5 978-3-319-10590-1},
  langid = {english},
  file = {/home/cristi/Zotero/storage/LJM85KDN/Zeiler and Fergus - 2014 - Visualizing and Understanding Convolutional Networks.pdf}
}

@book{zhangDiveDeepLearning2024,
  title = {Dive into Deep Learning},
  author = {Zhang, Aston and Lipton, Zachary and Li, Mu and Smola, Alexander J.},
  date = {2024},
  publisher = {Cambridge University Press},
  location = {Cambridge New York Port Melbourne New Delhi Singapore},
  abstract = {"Deep learning has revolutionized pattern recognition, introducing tools that power a wide range of technologies in such diverse fields as computer vision, natural language processing, and automatic speech recognition. Applying deep learning requires you to simultaneously understand how to cast a problem, the basic mathematics of modeling, the algorithms for fitting your models to data, and the engineering techniques to implement it all. This book is a comprehensive resource that makes deep learning approachable, while still providing sufficient technical depth to enable engineers, scientists, and students to use deep learning in their own work. No previous background in machine learning or deep learning is required—every concept is explained from scratch and the appendix provides a refresher on the mathematics needed. Runnable code is featured throughout, allowing you to develop your own intuition by putting key ideas into practice."--},
  isbn = {978-1-009-38943-3},
  langid = {english},
  pagetotal = {548},
  file = {/home/cristi/Zotero/storage/4R64URWR/Zhang et al. - 2024 - Dive into deep learning.pdf}
}

@article{zhangFastSensitiveGCaMP2023,
  title = {Fast and Sensitive {{GCaMP}} Calcium Indicators for Imaging Neural Populations},
  author = {Zhang, Yan and Rózsa, Márton and Liang, Yajie and Bushey, Daniel and Wei, Ziqiang and Zheng, Jihong and Reep, Daniel and Broussard, Gerard Joey and Tsang, Arthur and Tsegaye, Getahun and Narayan, Sujatha and Obara, Christopher J. and Lim, Jing-Xuan and Patel, Ronak and Zhang, Rongwei and Ahrens, Misha B. and Turner, Glenn C. and Wang, Samuel S.-H. and Korff, Wyatt L. and Schreiter, Eric R. and Svoboda, Karel and Hasseman, Jeremy P. and Kolb, Ilya and Looger, Loren L.},
  date = {2023-03-30},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {615},
  number = {7954},
  pages = {884--891},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-023-05828-9},
  url = {https://www.nature.com/articles/s41586-023-05828-9},
  urldate = {2025-05-15},
  abstract = {Abstract                            Calcium imaging with protein-based indicators               1,2               is widely used to follow neural activity in intact nervous systems, but current protein sensors report neural activity at timescales much slower than electrical signalling and are limited by trade-offs between sensitivity and kinetics. Here we used large-scale screening and structure-guided mutagenesis to develop and optimize several fast and sensitive GCaMP-type indicators               3–8               . The resulting ‘jGCaMP8’ sensors, based on the calcium-binding protein calmodulin and a fragment of endothelial nitric oxide synthase, have ultra-fast kinetics (half-rise times of 2\,ms) and the highest sensitivity for neural activity reported for a protein-based calcium sensor. jGCaMP8 sensors will allow tracking of large populations of neurons on timescales relevant to neural computation.},
  langid = {english},
  file = {/home/cristi/Zotero/storage/X69IRI3D/Zhang et al. - 2023 - Fast and sensitive GCaMP calcium indicators for imaging neural populations.pdf}
}
