{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps as cm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "\n",
    "import naplib as nl\n",
    "from naplib.visualization import strf_plot\n",
    "import thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thesis.utils.convert_to_npy(\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_response = thesis.load_data.load_response()\n",
    "raw_stimulus = thesis.load_data.load_stimulus()\n",
    "height, width = int(raw_response.shape[2]), int(raw_response.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gcd\n",
    "\n",
    "code_params = {\n",
    "    \"block_size\": gcd(width, height),\n",
    "    \"strf_fit_dtype\": np.float64,\n",
    "    \"strf_fit_batch_size\": 10,\n",
    "    \"sr_audio\": 250000,\n",
    "    \"sr_response\": 100,\n",
    "    \"max_lag\": 0.05,\n",
    "    \"end_stim\": 37500 / 250000,\n",
    "    \"max_epochs\": 150,\n",
    "}\n",
    "\n",
    "code_params[\"block_size\"] = (10, 10)\n",
    "code_params[\"strf_fit_dtype\"] = np.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make movie\n",
    "# frame_size = test_data.shape[1:3]\n",
    "\n",
    "# out_lossless = cv2.VideoWriter('test_video.mkv',cv2.VideoWriter_fourcc(*'FFV1'), 100, (frame_size[1], frame_size[0]))\n",
    "# out_lossy = cv2.VideoWriter('test_video_lossy.mkv',cv2.VideoWriter_fourcc(*'VP90'), 100, (frame_size[1], frame_size[0]))\n",
    "\n",
    "# cm_test_data = np.copy(test_data)\n",
    "\n",
    "# bwr_cm = cm.get_cmap('bwr')\n",
    "# cm_test_data = bwr_cm((test_data - np.min(test_data)) / (np.max(test_data) - np.min(test_data)))\n",
    "\n",
    "# cm_test_data = (cm_test_data[:, :, :, :3]*255).astype(np.uint8)\n",
    "\n",
    "# example_images = 100, 250, 400\n",
    "\n",
    "# for index, frame in enumerate(cm_test_data):\n",
    "#     if index in example_images:\n",
    "#         cv2.imwrite(f\"images/frame_{index}.png\", frame)\n",
    "#     out_lossless.write(frame)\n",
    "#     out_lossy.write(frame)\n",
    "# out_lossless.release()\n",
    "# out_lossy.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = int(code_params[\"sr_response\"] * code_params[\"max_lag\"])\n",
    "stimulus = raw_stimulus[:, : int(code_params[\"end_stim\"] * code_params[\"sr_audio\"])]\n",
    "response = raw_response[\n",
    "    :,\n",
    "    200\n",
    "    + delay : 200\n",
    "    + int(code_params[\"end_stim\"] * code_params[\"sr_response\"] + delay),\n",
    "    :,\n",
    "    :,\n",
    "]\n",
    "print(response.shape)\n",
    "small_response = thesis.preprocessing.smallify_response(\n",
    "    response, code_params[\"block_size\"]\n",
    ")\n",
    "small_height, small_width = small_response.shape[2], small_response.shape[3]\n",
    "small_response = small_response.reshape(\n",
    "    small_response.shape[0], small_response.shape[1], -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# clip response to stimulus start and normalize\n",
    "# = MinMaxScaler()\n",
    "f, t, Sxx = sp.signal.spectrogram(np.sum(stimulus, axis=0), fs=code_params[\"sr_audio\"])\n",
    "plt.pcolormesh(t, f, Sxx, cmap=\"bwr\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = thesis.generate.generate_spectrogram(\n",
    "    stimulus, response, sr_audio=code_params[\"sr_audio\"]\n",
    ")\n",
    "print(spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply STRF\n",
    "import pickle as pkl\n",
    "\n",
    "tmin = 0\n",
    "tmax = 0.3\n",
    "\n",
    "strf_model = nl.encoding.TRF(\n",
    "    tmin, tmax, code_params[\"sr_response\"], estimator=Ridge(10), show_progress=True\n",
    ")\n",
    "# resample\n",
    "print(f\"Size of raw stimulus is: {stimulus[0].shape}\")\n",
    "print(f\"Size of audio spectrogram is: {Sxx.shape}\")\n",
    "print(f\"After resampling: {spec.shape}\")\n",
    "\n",
    "\n",
    "def batch(X, y, batch_size):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[i : i + batch_size], y[i : i + batch_size]\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"test_coefs.pkl\", \"rb\") as file:\n",
    "        coef_ridge = pkl.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(spec.shape)\n",
    "    print(small_response.shape)\n",
    "\n",
    "    strf_X = np.array(spec, code_params[\"strf_fit_dtype\"])\n",
    "    strf_y = np.array(small_response, code_params[\"strf_fit_dtype\"])\n",
    "\n",
    "    strf_model.fit(X=strf_X, y=strf_y)\n",
    "    coef_ridge = strf_model.coef_\n",
    "    with open(\"test_coefs.pkl\", \"wb\") as file:\n",
    "        pkl.dump(strf_model.coef_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = [1, 120, 150, 240]\n",
    "avg_strf_list = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(6, 2.5))\n",
    "for i, pixel in enumerate(pixels):\n",
    "    model_1_coef = coef_ridge[pixel]\n",
    "    strf_plot(model_1_coef, tmin=tmin, tmax=tmax, ax=axes[i])\n",
    "    axes[i].set_title(f\"Ridge, Pixel {pixel}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_strf_list = np.array([np.mean(coef) for coef in coef_ridge])\n",
    "print(coef_ridge.shape)\n",
    "avg_response = np.mean(small_response, axis=(0, 1))\n",
    "avg_strf_list = avg_strf_list.reshape((small_height, small_width))\n",
    "avg_strf_list = (avg_strf_list - np.mean(avg_strf_list)) / (\n",
    "    np.max(avg_strf_list) - np.min(avg_strf_list)\n",
    ")\n",
    "plt.imshow(avg_strf_list, cmap=\"bwr\", vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "# plt.savefig(f\"../thesis_text/Imgs/m{animal_id}_r{recording_id}_t{trial_id}/avg_strf.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "from matplotlib import animation, cm\n",
    "\n",
    "temporal_avg_strf_list = np.mean(coef_ridge, axis=1)\n",
    "temporal_avg_strf_list = (temporal_avg_strf_list - np.mean(temporal_avg_strf_list)) / (\n",
    "    np.max(temporal_avg_strf_list) - np.min(temporal_avg_strf_list)\n",
    ")\n",
    "temporal_avg_strf_list = np.transpose(temporal_avg_strf_list)\n",
    "temporal_avg_strf_list = temporal_avg_strf_list.reshape(-1, small_height, small_width)\n",
    "\n",
    "frames = []\n",
    "fig = plt.figure()\n",
    "for frame in temporal_avg_strf_list:\n",
    "    frames.append([plt.imshow(frame, cmap=\"bwr\", vmin=-1, vmax=1, animated=True)])\n",
    "ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True, repeat_delay=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSTRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps as cm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.signal import resample, chirp\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "\n",
    "import naplib as nl\n",
    "from naplib.visualization import strf_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynamic_strf as dstrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from hdf5storage import loadmat\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import pytorch_lightning as plc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_data = np.array([block_reduce(frame, block_size=(10, 10), func=np.mean) for frame in data])\n",
    "# small_data = small_data.reshape(small_data.shape[0], small_data.shape[1], -1)\n",
    "print(small_response.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define builder and trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pl_bolts.callbacks.printing import PrintTableMetricsCallback\n",
    "\n",
    "### data naming\n",
    "crossval = True\n",
    "jackknife = False\n",
    "reduced = True\n",
    "logger = False\n",
    "res = f\"{small_height}x{small_width}\"\n",
    "\n",
    "desc_param = (\n",
    "    (\"jackk\" if jackknife else \"\")\n",
    "    + (\"crossval\" if crossval else \"\")\n",
    "    + (\"reduced\" if reduced else \"\")\n",
    "    + res\n",
    ")\n",
    "\n",
    "tb_logger = TensorBoardLogger(\n",
    "    f\"output/{desc_param}/logs\", name=f\"{desc_param}\", log_graph=False\n",
    ")\n",
    "\n",
    "\n",
    "def trainer():\n",
    "    return plc.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        precision=\"16-mixed\",\n",
    "        gradient_clip_val=10.0,\n",
    "        max_epochs=code_params[\"max_epochs\"],\n",
    "        logger=tb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        detect_anomaly=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=True,\n",
    "        enable_checkpointing=True,\n",
    "        callbacks=[PrintTableMetricsCallback()],\n",
    "    )\n",
    "\n",
    "\n",
    "def builder():\n",
    "    return dstrf.modeling.DeepEncoder(\n",
    "        input_size=spec.shape[2],\n",
    "        hidden_size=64,\n",
    "        channels=small_response.shape[2],\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_params[\"crossval\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dstrf_X = torch.from_numpy(spec)\n",
    "dstrf_y = torch.from_numpy(small_response)\n",
    "print(dstrf_X.shape)\n",
    "print(dstrf_y.shape)\n",
    "# dstrf_dataset = TensorDataset(dstrf_X, dstrf_y)\n",
    "# dataloader = DataLoader(dstrf_dataset, shuffle=True)\n",
    "# print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, ipynbname\n",
    "\n",
    "code_params[\"output_prefix\"] = f\"output/{desc_param}\"\n",
    "\n",
    "with open(\"code_params.yaml\", \"w\") as file:\n",
    "    yaml.dump(code_params, file)\n",
    "\n",
    "os.system(\n",
    "    f\"jupyter nbconvert --to script thesis.ipynb --output-dir {code_params['output_prefix']}\"\n",
    ")\n",
    "\n",
    "dstrf.modeling.fit_multiple(\n",
    "    builder=builder,\n",
    "    data=(dstrf_X, dstrf_y),\n",
    "    batch_size=10,\n",
    "    crossval=code_params[\"crossval\"],\n",
    "    jackknife=jackknife,\n",
    "    trainer=trainer,\n",
    "    save_dir=f\"{code_params['output_prefix']}/model\",\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob, os\n",
    "# checkpoints = sorted(glob.glob(os.path.join('output/5x128-jackknife-cv', 'model-*.pt')))\n",
    "# print(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dstrf.modeling.test_multiple(\n",
    "    model=builder(),\n",
    "    checkpoints=f\"{code_params['output_prefix']}/model\",\n",
    "    data=(dstrf_X[:1], dstrf_y[:1]),\n",
    "    crossval=code_params[\"crossval\"],\n",
    "    jackknife_mode=\"pred\",\n",
    ")\n",
    "scores.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.reshape((small_height, small_width))\n",
    "scores = np.nan_to_num(scores)\n",
    "plt.imshow(scores, cmap=\"bwr\", vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrf.estimate.dSTRF_multiple(\n",
    "    model=builder(),\n",
    "    checkpoints=f\"{code_params['output_prefix']}/model\",\n",
    "    data=dstrf_X[:1],\n",
    "    crossval=code_params[\"crossval\"],\n",
    "    save_dir=f\"{code_params['output_prefix']}/dstrf\",\n",
    "    chunk_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrf_path = f\"{code_params['output_prefix']}/dstrf/dSTRF-000.pt\"\n",
    "model_path = f\"{code_params['output_prefix']}/model/model-000.pt\"\n",
    "dstrf_model = torch.load(dstrf_path)\n",
    "cnn_model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dstrf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrf.visualize.dSTRF(\n",
    "    f\"{code_params['output_prefix']}/dstrf/dSTRF-000.pt\",\n",
    "    channels=slice(0, None, 1),\n",
    "    time_range=slice(0, None, 1),\n",
    "    output_prefix=f\"{code_params['output_prefix']}\",\n",
    "    vcodec=\"libx264\",\n",
    "    xlabel=\"Time lag (ms)\",\n",
    "    xticks=[0, 65],\n",
    "    xtick_labels=[-650, 0],\n",
    "    ylabel=\"Frequency\",\n",
    "    yticks=[0, 64],\n",
    "    ytick_labels=[\"20Hz\", \"60KHz\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(\n",
    "    ipd.Video(f\"{code_params['output_prefix']}/video/channel-0000.mkv\", height=300)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
